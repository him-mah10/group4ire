<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Group 4 | IRE Major Project</title>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" href="images/4.png" type="image/icon type">
    <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,900" rel="stylesheet">
    <link rel="stylesheet" href="fonts/icomoon/style.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="css/jquery-ui.css">
    <link rel="stylesheet" href="css/owl.carousel.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">
    <link rel="stylesheet" href="css/owl.theme.default.min.css">

    <link rel="stylesheet" href="css/jquery.fancybox.min.css">

    <link rel="stylesheet" href="css/bootstrap-datepicker.css">

    <link rel="stylesheet" href="fonts/flaticon/font/flaticon.css">

    <link rel="stylesheet" href="css/aos.css">

    <link rel="stylesheet" href="css/style.css">
    
  </head>
  <body data-spy="scroll" data-target=".site-navbar-target" data-offset="300">
  
  <div class="site-wrap">

    <header class="site-navbar py-4 bg-white js-sticky-header site-navbar-target">

      <div class="container">
        <div class="row align-items-center">
          
          <div class="col-6 col-xl-2">
            <h1 class="mb-0 site-logo"><a href="index.html" class="text-black h2 mb-0"><img src="images/ire.png" height="80px" width="80px"><span class="text-primary"></span> </a></h1>
          </div>
          <div class="col-12 col-md-10 d-none d-xl-block">
            <nav class="site-navigation position-relative text-right" role="navigation">

              <ul class="site-menu main-menu js-clone-nav mr-auto d-none d-lg-block">
                <li><a href="#aim-section" class="nav-link">Aim</a></li>
                <li><a href="#links-section" class="nav-link">Video and code link</a></li>
                <li><a href="#related-work-section" class="nav-link">Related Work</a></li>
                <li><a href="#methodologies-tried-section" class="nav-link">Methodologies tried</a></li>
                <li><a href="#architecture-section" class="nav-link">Architecture</a></li>
                <li><a href="#results-section" class="nav-link">Results</a></li>
                <li><a href="#analysis-section" class="nav-link">Analysis</a></li>
                <li><a href="#team-section" class="nav-link">Team</a></li>
              </ul>
            </nav>
          </div>


          <div class="col-6 d-inline-block d-xl-none ml-md-0 py-3" style="position: relative; top: 3px;"><a href="#" class="site-menu-toggle js-menu-toggle text-black float-right"><span class="icon-menu h3"></span></a></div>

        </div>
      </div>
      
    </header>

  
     
    <div class="site-blocks-cover overlay" style="background-image: url(images/alaska.jpg);" data-aos="fade">
      <div class="container">
        <div class="row align-items-center justify-content-center">

          <div class="col-md-12" data-aos="fade-up" data-aos-delay="400">
                        
            <div class="row mb-4">
              <div class="col-md-6">
                <h1>IRE Major Project</h1>
                <h2 class="mb-5 text-white">Event Coreference Resolution in Social Media Text</h2>
                <p class="mb-5">This is webpage for group 4 for IRE Major Project for Monsoon 2019 at IIIT Hyderabad.</p>
                <div>
                  <a href="./Group -4 _ Final Report.pdf" class="btn btn-primary mr-2 mb-2"><b>GET REPORT HERE</b></a>
                </div>
              </div>
            </div>

          </div>
        </div>
      </div>
    </div>  

    <div class="site-section" id="aim-section">
      <div class="container">
        <div class="row align-items-lg-left">
          <div class="col-md-12 text-left">
            <h2 class="section-title mb-3">Aim & Abstract</h2>
            <h2 class="section-sub-title mb-3">Aim</h2>
            <p class="mb-4 text-black">Goal of this project is to implement the Event Coreference algorithm proposed by Chao et al. in the paper "Selective Expression for Event Coreference Resolution on Twitter".</p>
            <h2 class="section-sub-title mb-3">Abstract</h2>
            <p class="mb-4 text-black">Event coreference is the problem of identifying and connecting mentions of the same events in different contexts. It is a fundamental problem in NLP with wide-spread applications.The given paper is the state-of-the-art for event coreference in Twitter. With the growth in popularity and size of social media, there is an urgent need for systems that can recognize the coreference relation between two event mentions in texts from social media. Approach till now basically depend upon NLP features which restricts domain scalability and leads to propagation error.In this paper a novel selective expression approach based on event trigger to explore the coreferential relationship in high-volume Twitter texts is proposed. Firstly a bidirectional Long Short Term Memory (Bi-LSTM) is exploited to extract the sentence level and mention level features. Then, to selectively express the essential parts of generated features, a selective gate is applied on sentence level features. Next, to integrate the time information of event mention pairs, an auxiliary feature is designed based on triggers and time attributes of the two event mentions. Finally, all these features are concatenated and fed into a classifier to
predict the binary coreference relationship between the event mention pair. They also released a new dataset called EventCoreOnTweet(ECT) dataset on which they evaluated their methods.It annotates the coreferential relationship between event mentions and event trigger of each event mention. The experimental results demonstrate that the approach achieves significant performance in the ECT dataset.
</p>
          </div>
        </div>
      </div>
    </div>


      <div class="site-section border-bottom bg-light" id="links-section">
      <div class="container">
        <div class="row align-items-lg-left">
          <div class="col-md-12 text-left">
            <h2 class="section-title mb-3">Video and code link</h2>
            <iframe width="1120" height="630" src="https://www.youtube.com/embed/iTEVcbhUscs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
            <br><br>
            <a href="https://github.com/him-mah10/IRE-Major-Project" class="btn btn-primary mr-3 mb-3">Get code here</a>
          </div>
        </div>
      </div>
    </div>

    <div class="site-section" id="related-work-section">
      <div class="container">
        <div class="row align-items-lg-left">
          <div class="col-md-12 text-left">
            <h2 class="section-title mb-3">Related Work</h2>
            <h2 class="section-sub-title mb-3">Jointly Multiple Events Extraction via Attention-based Graph
Information Aggregation</h2>
            <p class="mb-4 text-black">The paper talks about multiple events extraction from a sentence. A lot of work used sequential
modelling methods which suffered because long-range dependencies were not captured. In this
paper multiple events are extracted by introducing syntactic shortcut arcs to enhance
information flow and attention-based graph convolutional networks to model graph information.</p>
            
            <h2 class="section-sub-title mb-3">Improving Event Coreference Resolution by Modeling Correlations
between Event Coreference Chains and Document Topic Structures</h2>
            <p class="mb-4 text-black">This paper proposes a novel approach for event coreference resolution that models correlations
between event coreference chains and document topical structures
through an Integer Linear Programming formulation(ILP formulation).</p>
          </div>
        </div>
      </div>
    </div>

    <div class="site-section border-bottom bg-light" id="methodologies-tried-section">
      <div class="container">
        <div class="row align-items-lg-left">
          <div class="col-md-12 text-left">
            <h2 class="section-title mb-3">Methadologies Tired</h2>
            <p class="mb-4 text-black">
              Since the aim is to implement a paper most of the methodologies or the way to get the result has already been tried by the author. Our task is to replicate the results of the author. First we had to decide upon the framework to use. We decided to use Tensorflow since the author also used the same(and it was suggested by our mentor also). Next we created dataset using the method described below under the headings Data Collection and Dataset creation. We have discussed the NN implementation details below under the heading Implementation
            </p>
            <h2 class="section-sub-title mb-3">Data Collection</h2>
            <p class="mb-4 text-black">To reproduce the results we need to use the dataset used by the authors. However since they did not have permission to distribute the tweets themselves, they removed the terms, replacing them with “WORD” and left with instructions to create their dataset. Thus to  create their dataset we followed these instructions. First we extracted tweet ids from corpus.txt which they uploaded. Script to do so was created on the fly. Then we downloaded tweets corresponding to these tweet ids using api provided by tweepy. In total we got around 1994 tweets out of total of 2994 tweets that were mentioned. Since the collected data is only 67% of the actual dataset we do not expect results to same as the results of the author. Tweets which were missing were due to one of the following reasons: 
              <ol class="text-black">
<li class="text-black">User no longer exists</li>
<li class="text-black">Tweet no longer exists</li>
<li class="text-black">We didn’t have the permission to view the tweet.</li>
</ol> 
<p class="text-black">
After getting tweet we tokenized and pre-processed the tweets using the scripts provided by them and then we wrote a script to insert actual tweets using tweet ids in orignal corpus.txt file provided by the author. In case tweet is not available, we left it blank. All the code and dataset created could be found at: 
<a href="https://github.com/him-mah10/IRE-Major-Project/tree/master/Dataset">Link to dataset</a> 
</p>
            <br>
            <h2 class="section-sub-title mb-3">Dataset creation</h2>
            <p class="mb-4 text-black">
              <ol class="text-black">
              <li>From the data obtained using tweepy, we created the dataset for training(sentence pairs and label) and testing using the algorithm mentioned in the paper.
              </li>
              <li>For each event mention e, we paired it with all other event mentions which were tweeted in a time period of less than 7 days after e. 
              </li>
              <li>For each pair, we stored the event_mention_id for EM1, tweet_text for EM1, trigger_text for EM1, event_mention_id for EM2, tweet_text for EM2, trigger_text for EM2, label and timestamp difference between the pair.
              </li>
              <li>The event-mentions in a pair are considered co-referential(i.e. label=1), iff they have the same event_instance_id.
              </li>
            </ol>
            </p>

            <br>
            <h2 class="section-sub-title mb-3">Implementation</h2>
            <p class="mb-4 text-black">
              <ol class="text-black">
              <li>We indexed the unique words in the tweet_text and trigger_text for both train and test data.
              </li>
              <li>We used Glove twitter 100d embeddings to assign embeddings to words. If any word is not present in Glove, we assigned a [0]*100 embedding value to it. 
              </li>
              <li>We also calculated relative distance of each word from event trigger and sent it as input to model. The model initializes random distance embeddings and trains them along with others.
              </li>
              <li>We appended the word embedding and distance embedding and created final embedding for each word and passed it as input to BiLSTM.
              </li>
              <li>We coded the next layers in the network as specified in the paper.
              </li>
              <li>We divided the training data into batches of size 128. The number of epochs
required to train the data is not mentioned in the paper. Hence, for the time
being, we set the number of epochs to 5. We are trying to plot a graph of
accuracy (or loss) obtained vs the number of epochs. We are planning to do this
for number of epochs = 5 to 15 with an interval > 3.
              </li>
            </ol>
            </p>
          </div>
        </div>
      </div>
    </div>
  

    <section class="site-section" id="architecture-section">
      <div class="container">
        <div class="row align-items-lg-left">
          <div class="col-md-12 text-left">
            <h2 class="section-title mb-3">Architecture</h2>
            <p class="mb-4 text-black">The pairwise model consists of two parts, one for
            generating the semantic representation of event mention with
            recognized event trigger (parts a,b,c below)<a href="#fig1">(Figure 1)</a>, and the other for making
            the coreferential decision between two event mentions. (parts d below)<a href="#fig2">(Figure 2)</a>.</p>
            <h2 class="section-sub-title mb-3">a) Sentence and Mention Level Features</h2>
            <p class="mb-4 text-black">After pre-processing each segmented token in a tweet will be transformed into an
embedding vector. The embedding vector consists of two parts: word embedding and
distance embedding. Word2vec was used to pre-train word embedding, and label
<i>< unknown ></i> ​ to represent the out of vocabulary (OOV) words. Words that are close to
event trigger have more semantic relevance which is captured by distance embeddings.
Bi-LSTMs contains two parts LSTM​<sub>f</sub> and
LSTM​<sub>b​</sub> . LSTM​<sub>f</sub> captures
left context and LSTM​<sub>b</sub>
captures right context. Output of both of them are concatenated and fed to selective
gate. The sentence level feature (dashed rectangle in the left of figure above) is a
sequence of each word’s context feature in tweet when tweet as input where n is the
length of tweet.<br><center class="text-black">
h​<sub>f,i</sub> ​ = LSTM​<sub>f</sub>​[x​<sub>i</sub>​ , h​<sub>f,i-1​</sub> ]<br>
h​<sub>b,i</sub> ​ = LSTM​<sub>b</sub>​[x​<sub>i</sub>​ , h​<sub>b,i+1​</sub> ]<br>
h​<sub>i</sub>​ = [h​<sub>f,i​</sub> , h​<sub>b,i​</sub> ]<br>
Sent<sub>level</sub> ​ = (h<sub>0</sub> ​ ​ , h<sub>1</sub> ​ , h<sub>2</sub> ​ ​ , ..., h<sub>n</sub> )</center><p class="text-black"> ​
And the mention level feature (dashed rectangle in the right of the figure above) is the
concatenation of the last output of forward and backward LSTM cell when event trigger
as input where m is the length of event trigger.<br></p>
<center class="text-black">Ment<sub>level</sub>​ = [h<sub>f,m</sub>​ , h<sub>b,0</sub>] ​</center>
            </p>
            <h2 class="section-sub-title mb-3">b) Selective Expression</h2>
            <p class="mb-4 text-black">
              Each word plays a different role for one specific event trigger in the same sentence.
Some are core words, while another portion of words is semantically confusing.
Therefore selective expression mechanisms were employed to achieve more accurate
latent features of event mentions by limiting the semantic expression of unimportant or
irrelevant words according to the event trigger. ‘Select’ represents the selective
representation of event mentions.<br><center class="text-black">
R​<sub>c​</sub> = h​<sub>i</sub>​ ∗ Ment​<sub>level</sub><br>
α​<sub>i</sub>​ = tanh(W​<sub>s</sub>​ · R​<sub>c</sub>​ + b​<sub>s</sub>​ )<br>
Select = α ∗ Sent​<sub>level</sub></center>
            </p>
            <h2 class="section-sub-title mb-3">c) Attention Mechanism</h2>
            <p class="mb-4 text-black">
              If there are different event mentions in a tweet, the semantic contribution of each word in
the tweet to an event mention’s semantic representation is varied. Therefore attention
mechanisms is used to compute the importance score for each word’s selective
expression to reflect the different contributions to semantic representation of each event
mention. Then the importance scores are normalized to obtain the latent feature by the
weighted sum.<br><center class="text-black">
u​<sub>i​</sub> = V​<sub>a</sub>​<sup>T</sup>​ tanh(W​<sub>a</sub>​Select​<sub>i</sub>​ + b​<sub>a​</sub> )<br>
β​<sub>i</sub> =exp(u​<sub>i​</sub>)/ (Σ exp(u​<sub>i​</sub>))<br>
latent = Σβ​<sub>i</sub> Select<sub>i</sub><br>
V​<sub>em​</sub> = [latent, Ment​<sub>level​</sub> ]<br></center>
            </p>
            <h2 class="section-sub-title mb-3">d) Coreference Decision</h2>
            <p class="mb-4 text-black">
              To determine coreference between two event mentions the second part of the
architecture receives the semantic representation of two event mentions V​<sub>em​</sub><sup>1</sup> and
V​<sub>em</sub><sup>2</sup>
along with V​<sub>local​</sub><sup>1,2</sup> where V​<sub>local​</sub><sup>1,2</sup> captures the number of words in the overlap between
event triggers and number of days between two event mention.<br><center class="text-black">
V​<sub>pair​</sub> = (​ V<sub>em</sub><sup>1</sup>​ , V​<sub>em​</sub><sup>2</sup>​ , V​<sub>local​</sub><sup>1,2​</sup> )<br>
V​<sub>local​</sub> 1,2 ​ = (V​<sub>w​</sub> , V​<sub>d​</sub> )</center><br><p class="mb-4 text-black">
V​<sub>W​</sub> : The number of words in the overlap between event triggers.<br>
V​<sub>D​</sub> : The number of days between two event mention.<br>
The pairwise features are processed by a simple neural network layer to calculate the
distributed similarity<br><center class="text-black">
V​<sub>ds​</sub> = relu(W​<sub>ds​</sub> · V​<sub>pair​</sub> + b​<sub>ds​</sub> )</center></p><p class="text-black">
A softmax layer is applied finally to calculate the probability of two categories
(coreferential and not coreferential)<br><center class="text-black">
Score = Softmax(W​<sub>pro​</sub> · V​<sub>ds</sub> + b​<sub>pro</sub> )</center></p>
            </p>
            <br>
            <br>
            <p class="mb-4"><img src="images/fig1.png" id="fig1" height="700px" alt="figure 1" ></p>
            <br>
            <p class="mb-4"><img src="images/fig2.png" id="fig2" height="750px" alt="figure 1" ></p>
          </div>
        </div>
      </div>
    </section>



    <section class="site-section border-bottom bg-light" id="results-section">
      <div class="container">
        <div class="row align-items-lg-left">
          <div class="col-md-12 text-left">
            <h2 class="section-title mb-3">Evaluation Mechanism & Results</h2>
            <p class="mb-4 text-black">
              Hyperparameter settings
              <table border="1" cellpadding="10" class="mb-4 text-black">
                <tr>
                  <td>Batch size</td>
                  <td>128</td>
                </tr>
                <tr>
                  <td>LSTM size</td>
                  <td>128</td>
                </tr>
                <tr>
                  <td>Attention size</td>
                  <td>128</td>
                </tr>
                <tr>
                  <td>Co-reference size</td>
                  <td>128</td>
                </tr>
                <tr>
                  <td>Word embedding size+Distance embedding
size</td>
                  <td>100+14</td>
                </tr>
                <tr>
                  <td>Learning rate</td>
                  <td>0.01</td>
                </tr>
                <tr>
                  <td>Number of epochs</td>
                  <td>5</td>
                </tr>
              </table>
              <p class="mb-4 text-black">
              We divided the test dataset into batches of size 128.
We will report results in terms of Accuracy(A), Precision (P), Recall (R) and F1 -score (F1) using
commonly-used coreference scoring algorithms given by the CoNLL scorer to evaluate the
event coreference resolution system.
<br>Results to be updated.
          </div>
        </div>
      </div>
    </section>


    <section class="site-section" id="analysis-section">
      <div class="container">
        <div class="row align-items-lg-left">
          <div class="col-md-12 text-left">
            <h2 class="section-title mb-3">Analysis</h2>
            <p class="mb-4 text-black">
              <ol>
                <li>
                  We see that our system is able to perform the task of coreference resolution but the
results are not that great. The reason is the dataset size. Since a lot of tweets are
missing, the performance of the system is adversely affected.
                </li>
                <li>
                  For two tweets which has co-reference, even if one of the tweets goes missing, the other
is of no use to us and thus training example size is greatly reduced affecting the
performance of the system.
                </li>
                <li>
                  Also, we observed that in pre-processing stage of raw twitter data that, some event
triggers are not a part of their corresponding tweets. Example: ‘call’ is event trigger
whereas ‘calls’ is present in event mention (The code for pre-processing twitter data is
made available by the authors. We used that as it is)
                </li>
                <li>
                  We would also like to add that using Glove embeddings instead of word2vec
embeddings trained on the given training data increased the efficiency of model.
                </li>
                <li>
                  Using BiLSTM produced better results than using LSTM even for event triggers(though
they are small in length and don’t have heavy long-distance interdependencies)
                </li>
                <li>
                  Overall, this paper uses a really efficient network to solve coreference resolution
problem.
                </li>
                <li>
                  We also looked at the two papers mentioned in ‘Related Work’ section and are thinking
of ways to combine those ideas with our current approach to produce a more efficient
model.
                </li>
              </ol>
            </p>
          </div>
        </div>
      </div>
    </section>



    <section class="site-section border-bottom text-black bg-light" id="team-section">
      <div class="container">
        <div class="row mb-5">
          <div class="col-12 text-center">
            <h2 class="section-title mb-3">Team</h2>
          </div>
        </div>
        <div class="row">
          <div class="col-md-6 col-lg-3 mb-5 mb-lg-0" data-aos="fade" data-aos-delay="100">
            <div class="person text-center">
              <img src="images/himanshu.jpg" alt="Image" class="img-fluid rounded-circle w-50 mb-5">
              <h3>Himanshu Maheshwari</h3>
              <p class="position">20171033</p>
              
            </div>
          </div>
          <div class="col-md-6 col-lg-3 mb-5 mb-lg-0" data-aos="fade" data-aos-delay="200">
            <div class="person text-center">
              <img src="images/sravya.jpg" alt="Image" class="img-fluid rounded-circle w-50 mb-5">
              <h3>Sri Satya Sravya Pulle</h3>
              <p class="position">20161079</p>
            </div>
          </div>
          <div class="col-md-6 col-lg-3 mb-5 mb-lg-0" data-aos="fade" data-aos-delay="300">
            <div class="person text-center">
              <img src="images/nitish.jpg" alt="Image" class="img-fluid rounded-circle w-50 mb-5">
              <h3>Nitish Dwivedi</h3>
              <p class="position">2018201068</p>
            </div>
          </div>
          <div class="col-md-6 col-lg-3 mb-5 mb-lg-0" data-aos="fade" data-aos-delay="300">
            <div class="person text-center">
              <img src="images/rushit.jpg" alt="Image" class="img-fluid rounded-circle w-50 mb-5">
              <h3>Rushit Jasani</h3>
              <p class="position">2018201034</p>
            </div>
          </div>
        </div>
      </div>
    </section>
    

  </div> <!-- .site-wrap -->

  <script src="js/jquery-3.3.1.min.js"></script>
  <script src="js/jquery-migrate-3.0.1.min.js"></script>
  <script src="js/jquery-ui.js"></script>
  <script src="js/popper.min.js"></script>
  <script src="js/bootstrap.min.js"></script>
  <script src="js/owl.carousel.min.js"></script>
  <script src="js/jquery.stellar.min.js"></script>
  <script src="js/jquery.countdown.min.js"></script>
  <script src="js/bootstrap-datepicker.min.js"></script>
  <script src="js/jquery.easing.1.3.js"></script>
  <script src="js/aos.js"></script>
  <script src="js/jquery.fancybox.min.js"></script>
  <script src="js/jquery.sticky.js"></script>

  
  <script src="js/main.js"></script>
    
  </body>
</html>
